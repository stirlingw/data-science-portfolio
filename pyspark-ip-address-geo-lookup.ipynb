{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark IP Address Geo Lookup\n",
    "- Shamelessly adopted code from (https://github.com/adampolomski/prism/blob/master/tools/wppl.py)\n",
    "\n",
    "## Install GeoIP2 Along With PySpark\n",
    "- sudo pip install geoip2\n",
    "- http://geoip2.readthedocs.io/en/latest/#city-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed PySpark Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoip2.database\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize PySpark\n",
    "- `local[*]` sets PySpark to utilize all processors on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\\\n",
    "                .setMaster(\"local[*]\")\\\n",
    "                .setAppName(\"pysparkIPAddressGeoLookup\")\n",
    "        \n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder.appName(\"spark play\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prove GeoIP2 is got imported properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geoip2.models.City({'city': {'geoname_id': 2759794, 'names': {'de': 'Amsterdam', 'en': 'Amsterdam', 'es': 'Ámsterdam', 'fr': 'Amsterdam', 'ja': 'アムステルダム', 'pt-BR': 'Amesterdão', 'ru': 'Амстердам', 'zh-CN': '阿姆斯特丹'}}, 'continent': {'code': 'EU', 'geoname_id': 6255148, 'names': {'de': 'Europa', 'en': 'Europe', 'es': 'Europa', 'fr': 'Europe', 'ja': 'ヨーロッパ', 'pt-BR': 'Europa', 'ru': 'Европа', 'zh-CN': '欧洲'}}, 'country': {'geoname_id': 2750405, 'is_in_european_union': True, 'iso_code': 'NL', 'names': {'de': 'Niederlande', 'en': 'Netherlands', 'es': 'Holanda', 'fr': 'Pays-Bas', 'ja': 'オランダ王国', 'pt-BR': 'Holanda', 'ru': 'Нидерланды', 'zh-CN': '荷兰'}}, 'location': {'accuracy_radius': 100, 'latitude': 52.3556, 'longitude': 4.9135, 'time_zone': 'Europe/Amsterdam'}, 'postal': {'code': '1091'}, 'registered_country': {'geoname_id': 2750405, 'is_in_european_union': True, 'iso_code': 'NL', 'names': {'de': 'Niederlande', 'en': 'Netherlands', 'es': 'Holanda', 'fr': 'Pays-Bas', 'ja': 'オランダ王国', 'pt-BR': 'Holanda', 'ru': 'Нидерланды', 'zh-CN': '荷兰'}}, 'subdivisions': [{'geoname_id': 2749879, 'iso_code': 'NH', 'names': {'de': 'Nordholland', 'en': 'North Holland', 'es': 'Holanda Septentrional', 'fr': 'Hollande-Septentrionale', 'pt-BR': 'Holanda do Norte', 'ru': 'Северная Голландия'}}], 'traits': {'ip_address': '5.153.63.162'}}, ['en'])\n"
     ]
    }
   ],
   "source": [
    "cityReader = geoip2.database.Reader(r'GeoLite2-City.mmdb')\n",
    "city = cityReader.city(\"5.153.63.162\")\n",
    "print(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Dataframe Example\n",
    "- user_id\n",
    "- ip_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|user_id|    ip_address|\n",
      "+-------+--------------+\n",
      "|      0|  5.153.63.162|\n",
      "|      1|  159.8.223.72|\n",
      "|      2|  169.38.84.49|\n",
      "|      3|  23.246.195.8|\n",
      "|      4|158.176.86.249|\n",
      "+-------+--------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = [(0, \"5.153.63.162\"), (1, \"159.8.223.72\"), (2, \"169.38.84.49\"), (3, \"23.246.195.8\"), (4, \"158.176.86.249\")]\n",
    "events_df = spark.createDataFrame(data, [\"user_id\", \"ip_address\"])\n",
    "print(events_df.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates a function that returns a new enriched row with geo information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityReader = geoip2.database.Reader(r'GeoLite2-City.mmdb')\n",
    "\n",
    "def asEnrichedRow(lines):\n",
    "    for line in lines:\n",
    "        try:\n",
    "            if len(line[\"ip_address\"]) > 7:\n",
    "                city = cityReader.city(line[\"ip_address\"])\n",
    "                yield Row(\n",
    "                    user_id=line[\"user_id\"], \n",
    "                    ip_address=line[\"ip_address\"],\n",
    "                    local_timezone=city.location.time_zone, \n",
    "                    city=city.city.name, \n",
    "                    country=city.country.name, \n",
    "                    latitude = city.location.latitude, \n",
    "                    longitude = city.location.longitude)\n",
    "        except GeneratorExit:\n",
    "            return\n",
    "        except:\n",
    "            \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PySpark to call the function above and extract geo information\n",
    "- Differences between mapPartitions() and map()\n",
    "    - https://stackoverflow.com/questions/49142373/what-is-the-difference-between-mappartitions-and-foreachpartition-in-apache-spar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_events_df = events_df.rdd.mapPartitions(asEnrichedRow)\\\n",
    "                                   .map(lambda r: (\n",
    "                                        r.user_id, \n",
    "                                        r.ip_address, \n",
    "                                        r.local_timezone, \n",
    "                                        r.city, \n",
    "                                        r.country, \n",
    "                                        r.latitude, \n",
    "                                        r.longitude))\\\n",
    "                                   .toDF()\\\n",
    "                                   .select(\n",
    "                                        col(\"_1\").alias(\"user_id\"),\n",
    "                                        col(\"_2\").alias(\"ip_address\"),\n",
    "                                        col(\"_3\").alias(\"local_timezone\"),\n",
    "                                        col(\"_4\").alias(\"city\"),\n",
    "                                        col(\"_5\").alias(\"country\"),\n",
    "                                        col(\"_6\").alias(\"latitude\"),\n",
    "                                        col(\"_7\").alias(\"longitude\")\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, we have a PySpark dataframe w/ Geo Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------------+---------+-------------+--------+---------+\n",
      "|user_id|    ip_address|  local_timezone|     city|      country|latitude|longitude|\n",
      "+-------+--------------+----------------+---------+-------------+--------+---------+\n",
      "|      0|  5.153.63.162|Europe/Amsterdam|Amsterdam|  Netherlands| 52.3556|   4.9135|\n",
      "|      1|  159.8.223.72|Europe/Amsterdam|Amsterdam|  Netherlands| 52.3556|   4.9135|\n",
      "|      2|  169.38.84.49|    Asia/Kolkata|  Chennai|        India| 13.0833|  80.2833|\n",
      "|      3|  23.246.195.8| America/Chicago|   Dallas|United States| 32.7787| -96.8217|\n",
      "|      4|158.176.86.249|            null|     null|United States|  37.751|  -97.822|\n",
      "+-------+--------------+----------------+---------+-------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enriched_events_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
